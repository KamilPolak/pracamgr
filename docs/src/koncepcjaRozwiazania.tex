\chapter{Koncepcja rozwiązania}

W niniejszym rozdziale skupiam się na opisie koncepcji rozwiązania wykorzystania
analizy sentymentu, sieci społecznych i geolokacji w analizie zachowań
użytkowników serwisów społecznościowych. W kolejnych podrozdziałach opisuję
sposoby w jaki dane zagadnienia zostały zaaplikowane w moich badaniach.
Na początku przedstawiam gruboziarnisty model systemu (\ref{section:modelsystemu}),
który prezentuje jego najważniejsze moduły. Następnie opisuję tematykę
i sposób gromadzenia danych (\ref{section:gromadzeniedanych}) potrzebnych do 
przeprowadzenia analizy internautów. Później omawiam metodę jaką zastosowałem 
podczas analizy sentymentu (\ref{section:analizasentymentu}) wpisów użytkowników.
W dalszej kolejności skupiam się nad zastosowanymi
sposobami analizy sieci społecznych (\ref{section:siecispoleczne})
i całość kończę omówieniem wykorzystania geolokacji w moich badaniach 
(\ref{section:wykorzystaniegeolokacji}).








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% MODEL SYSTEMU
\section{Model systemu}
\label{section:modelsystemu}
Stworzony system zbudowany jest z kilku modułów. Wyróżnić można jego
trzy główne części:
\begin{itemize}
  \item gromadzenie danych,
  \item przetwarzanie danych,
  \item analiza zebranych danych.
\end{itemize} 
Wszystkie informacje zapisywanie są w jednej, centralnej bazie danych.
Schemat systemu zaprezentowany jest na rysunku 
\ref{image:gruboziarnisty-model-systemu}.


\clearpage

\begin{figure}[ht!]
\centering
\includegraphics[width=140mm]{img/budowa-systemu.png}
\caption{Gruboziarnisty model systemu}
\label{image:gruboziarnisty-model-systemu}
\end{figure}

Każda z wyróżnionych powyżej części systemu bierze udział w innym etapie
badań. Na początku najważniejsze jest gromadzenie danych, po którym następuje
ich przetwarzanie by na końcu zająć się analizą i próba ekstrakcji wiedzy.
Wszystkie te części są ze sobą połączone wspólną bazą danych, w której
przechowywana jest zgromadzona wiedza i wyniki przetwarzania i analizy danych.
Poniżej pokrótce omówione są wszystkie z tych części.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% GROMADZENIE DANYCH
\section{Gromadzenie danych}
\label{section:gromadzeniedanych}
W tej sekcji opisuję sposób przeprowadzenia początkowych prac związanych
z moimi badaniami, które związane były ze zgromadzeniem danych potrzebnych
do przeprowadzania analiz. Etap ten był niezwykle istotny i przeprowadzenie
go umożliwiło dalsze prace. Zgromadzone dane pochodzą z serwisu Twitter
i zostały uzyskane przy pomocy udostępnionego publicznie API (interfejsu
programistycznego).

\subsection{Tematyka danych}
% piłka nożna, kibice
Aby przeprowadzić analizę danych koniecznym było wybranie podzbioru
użytkowników Twittera. Dwa aspekty zadecydowały o tym, że skupiono się nad
analizą anglojęzycznego środowiska piłkarskiego:
\begin{itemize}   
  \item struktura językowa użytkowników sieci Twitter -- według badań firmy Gnip
  \cite{GnipTwitterLanguages} (zajmującej się gromadzeniem danych z tego serwisu
  społecznościowego) w 2013 roku ponad 50\% tweetów wysłanych zostało w języku
  angielskim.
  Dla porównania w języku polskim było to zaledwie 0.11\%.
  Dlatego też badanie użytkowników anglojęzycznych ma największy sens, gdyż
  prowadzi do zebrania największej liczby tweetów.
  Wybór konkretnego języka komunikacji jest o tyle istotny, iż wpływa znacznie
  na część badań związaną z analizą sentymentu,
  \item dynamika wpisów na Twitterze -- w związku z narzuconym w serwisie
  ograniczeniem na liczbę znaków wpisu (140) oraz sposobem ich prezentowania
  użytkownikom na ich stronie głównej (chronologicznie od najnowszych) serwis
  ten charakteryzuje się wysoką dynamiką informacji wysyłanych przez użytkowników.
  Wpisy bardzo często odnoszą się do aktualnych wydarzeń, krótko je komentując.
  W związku z tym badanie środowiska piłkarskiego ma duży sens, gdyż zainteresowani
  futbolem internauci mają wiele tematów do dyskusji -- komentowanie spotkań na żywo,
  refleksje po meczach i dyskusje między spotkaniami.
  W profesjonalnych ligach piłkarskich mecze odbywają się co najmniej raz w tygodniu,
  a informacje o stanie kadrowym, kontuzjach i nadziejach przed meczem
  rozpalają kibiców swoich drużyn. W związku z wysoką dynamiką świata piłkarskiego,
  użytkownicy Twittera będący kibicami tworzą proporcjonalnie dużą liczbę
  tweetów -- komentując na biężąco wszelkie wydarzenia. Dlatego też wybór
  tej podgrupy do moich badań jest racjonalny i daje możliwość zbadania 
  zachowań użytkowników społecznościowych dostarczając wiele wpisów, na których
  można przeprowadzić analizy.
\end{itemize}  


\subsection{Sposób zbierania danych}
% wybrane kluby, słowa kluczowe, API, nasłuchiwanie
Aby uzyskać jak najlepsze rezultaty zbierania danych ze środowiska piłkarskiego
(posługującego się językiem angielskim) jako dziedzinę badań wybrano
najwyższą klasę rozgrywek piłki nożnej mężczyzn w Anglii (i Walii),
czyli Premier Leauge -- uznawaną przez wielu ekspertów za najsilniejszą ligę na
świecie. Co istotne, jest to także najczęściej oglądana liga piłkarska.
Średnio pojedynczy mecz ma widownię ponad 12 milionów osób
(\cite{PremierLeagueAudience}) bijąc ponad dwukrotnie oglądalność innych lig 
(włoskiej, hiszpańskiej czy niemieckiej).

Zbieranie danych odbywało się przy pomocy Twitter Stream API -- oficjalnie
udostępnionego interfejsu programistycznego.
Aby móc zbierać wpisy należy napisać program -- robota internetowego,
korzystającego z API, który nasłuchuje na żywo pojawiających się wpisów.

Technika ta ma jednak ograniczenia i pozwala na konsumowanie maksymalnie 1\%
wszystkich pojawiających się w tym czasie wpisów na Twitterze (aby uzyskać
wszystkie wpisy należy wnieść opłatę w serwisach partnerskich).

Do nasłuchiwania wpisów koniecznym jest także zdefiniowanie filtrów
określających jakie dane nas interesują. Twitter wymaga by podać przynajmniej
jeden z niniejszych: słowa kluczowe, identyfikatory użytkowników lub obszary
geograficzne. Dodatkowo możliwe jest podanie innych parametrów, jak na przykład
języka wpisów. Dlatego też zdecydowałem się korzystać z filtra słów kluczowych
wraz z ograniczeniem wpisów na język angielski.

Twitter Stream API dostarcza jedynie tweetów pojawiających się w czasie
rzeczywistym. Oznacza to, że możemy przy jego użyciu mieć jedynie dostęp do tych
wpisów, które zostały wysłane, gdy jednocześnie uruchomiony był nasz program
nasłuchujący. Aby zmaksymalizować jakość i zakres zebranych danych program
nasłuchujący uruchamiany był w trakcie odbywania się meczów 
(z kilkudziesięciuminutowym zapasem czasowym przed i po spotkaniu).

W związku z koniecznością określania słów kluczowych ograniczono liczbę
śledzonych klubów do najlepszej czwórki sezonu 2012/2013, którą tworzą:
Manchester United FC, Manchester City FC, Chelsea FC oraz Arsenal FC.
Są to więc odpowiednio dwa kluby z Manchesteru i dwa z Londynu.

Mecze nasłuchiwano od 23 listopada do 29 grudnia 2013 roku. W tym czasie odbyło
się 9 kolejek spotkań (od 12 do 19 kolejki włącznie). Jako słowa kluczowe przed
każdym meczem definiowane były: nazwiska i znane określenia
piłkarzy, nazwiska i znane określenia trenerów (menadżerów) drużyn, nazwy i
określenia klubów, nazwisko głównego sędziego i nazwa stadionu. 
Oprócz meczów Premier League nasłuchiwano także dwóch kolejek Ligi Mistrzów
z udziałem wyżej wymienionych zespołów, które odbyły się w tym czasie.

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ANALIZA SENTYMENTU
\section{Analiza sentymentu}
\label{section:analizasentymentu}
W tym miejscu opisuję sposób w jaki została użyta do moich badań analiza
wydźwięku wypowiedzi. Przedstawiam czynności wstępne jakie zostały zastosowane
na tekście, prezentuję krótko wybrany algorytm i zastosowane w nim modyfikacje
oraz opisuję sposób zaaplikowania analizy wydźwięku na zgromadzonych tweetach.

\subsection{Normalizacja tekstu}
% pozbycie się słów kluczowych, zaprzeczenia, retweety

W związku z tym, że wpisy są tworzone przez zwykłych użytkowników posiadają one
wiele znaków i elementów, które z punktu widzenia analizy sentymentu są zbędne,
a czasami prowadzące do błędów. Dlatego też tekst należy poddać normalizacji,
usunięciu zbędnych elementów, szumów i spamu. Przykładowa lista wpisów jakie
znalazły się w zgromadzonych danych przedstawia poniższa tabela
(\ref{tab:wpisy-przed-normalizacja}).


\begin{table}[ht!]  
\begin{center}  
\begin{tabular}{|r|p{140mm}|}
\hline
\multicolumn{2}{|c|}{Przed normalizacją}
\\ \hline
1 & RT @J\_SPEKZ: Haha quality! \#Fellaini \#United \#Moyes
http://t.co/rJB4K1fvZy
\\ \hline
2 & Stay woke brah! The Arsenal is about to make everything alright soon :) RT
@JCphoenixx: So damn tired, So not sleepy.
\\ \hline
3 & @abdul1haseeb My arsenal is not disappointing too :P 
\\ \hline
4 & @Arsenal didn't think i could respect @aaronramsey any more than i already
did, bute what a gentleman he is for not to celebrate that goal:) 
\\ \hline
5 & BENDTNER!!! ARE YOU FUCKING SERIOUS!! Even though im not arsenal fan :o
\\ \hline
6 & Haha, you gotta agree, no one gets booed like Manchester United :D \#ZeDevilza
\\
\hline
\end{tabular} 
\end{center} 
\caption{Przykładowa lista wpisów przed normalizacją}
\label{tab:wpisy-przed-normalizacja}
\end{table}


Po przeprowadzeniu wszystkich prac związanych z normalizacją tekstu wpisy z
powyższej tabeli prezentują się w następujący sposób:

\begin{table}[ht!]  
\begin{center}  
\begin{tabular}{|r|p{140mm}|}
\hline
\multicolumn{2}{|c|}{Po normalizacji}
\\ \hline
1 & 
\\ \hline
2 & Stay woke brah make alright
\\ \hline
3 & not\_disappointing
\\ \hline
4 & didnt not\_respect bute gentleman not\_celebrate not\_goal
\\ \hline
5 & FUCKING im not\_fan
\\ \hline
6 & haha gotta agree not\_booed
\\
\hline
\end{tabular} 
\end{center} 
\caption{Lista wpisów poddanych normalizacji}
\label{tab:wpisy-po-normalizacja}
\end{table}

\clearpage
Kolejne kroki, które przekształciły tweety do powyższej postaci to:
\begin{enumerate}
  \item Usunięcie skomentowanych retweetów.\\
  \texttt{Stay woke brah! The Arsenal is about to make everything
  alright soon :) \sout{RT @JCphoenixx: So damn tired, So not sleepy.}}
  
  \item Usunięcie skomentowanych cytowań. \\
  \texttt{At all...\sout{"@dotun\_somoye: Even city's first goal
  negredo was offside....:( the refs not helping at all"} }
  
  \item Usunięcie hiperlinków.\\
  \texttt{You up for Arsenal's match later on? - what time? maybe if i'm not
  busy baby sitting :) \sout{http://t.co/aC5Ec8ipy1}}
 
  
  \item Usunięcie nazw użytkowników.\\
  \texttt{\sout{@abdul1haseeb} My arsenal is not disappointing too :P}
  
  
  \item Usunięcie hashtagów. \\
  \texttt{Haha, you gotta agree, no one gets booed like Manchester United :D
  \sout{\#ZeDevilza}}
  
  
  \item Oznaczenie wyrazów zaprzeczonych przedrostkiem \texttt{NOT\_} (opisuję
  dokładniej w sekcji \ref{subsection:sentyment-algorytm}). \\
  \texttt{didn't \textbf{NOT\_think NOT\_i NOT\_could NOT\_respect NOT\_any 
  NOT\_more NOT\_than NOT\_i NOT\_already NOT\_did}, bute what a gentleman he 
  is for not \textbf{NOT\_to NOT\_celebrate NOT\_that NOT\_goal:)}}

 \item Zachowanie tylko znaków alfabetu:
  	\begin{itemize}
  		\item usunięcie zaimków dzierżawczych (\texttt{Helen's} $\to$ \texttt{Helen}),
  		\item usunięcie apostrofu ze skróconych zaprzeczeń (\texttt{don't} $\to$ \texttt{dont}),
  		\item normalizacja liter diakrytyzowanych (\texttt{José Mourinho} $\to$ \texttt{Jose
  		Mourinho})
  		\item usunięcie liczb i wszelkich znaków niealfabetycznych.
	\end{itemize}

  \texttt{You up for Arsenal\sout{'s} match later on\sout{? -} what
  time\sout{?} maybe if i\sout{'}m not busy baby sitting \sout{:)}} 
	
	\item Usunięcie wyrazów zdefiniowanych w stop liście (powszechne wyrazy danego
	języka, które mogą być pominięte nie tracąc jednocześnie żadnej informacji).
	Zastosowałem stop listę z serwisu \mbox{WebPageAnalyse.com} 
	(\cite{WebPageAnalyse}) zawierającą 528 słów.

	\texttt{\sout{You up for} Arsenal match \sout{later on what} time \sout{maybe if} 
 	im \sout{not} busy baby sitting}
	
	\item Usunięcie słów kluczowych, które użyte były do gromadzenia wpisów z
	Twittera -- czyli nazwisk piłkarzy, menadżerów, nazw klubów, itd.
	
	\texttt{\sout{BENDTNER} FUCKING im \sout{NOT\_arsenal} NOT\_fan}
	
\end{enumerate}





\subsection{Algorytm i jego modyfikacja}
\label{subsection:sentyment-algorytm}
% + dobór parametrów, emotikony, zaprzeczenia

Do przeprowadzenia analizy sentymentu na zebranych tweetach skorzystałem z
metody opracowanej przez Alexandra Paka i Patricka Paroubek'a, którą
krótko przedstawiłem w sekcji \ref{subsubsection:pakandparoubek}.
Jest to technika, która pozwala badać sentyment bez słownika sentymentu.
Pierwszym krokiem jest zbudowanie słownika z zebranych danych.
W tym celu wybiera się podzbiór wpisów, które zawierają emotikony.
W związku ze 140 znakowym ograniczeniem na długość znaków przyjmuje się
założenie, że dana emotikona nadaje wydźwięk całemu wpisowi.
Według artykułu \cite{EmoticonAnalysisTwitter} 20 emotikon pokrywa
w 90\% stosowanie tych znaków graficznych we wpisach (na 100 wpisów z
emotikonami, 90 z nich zawiera emotikonę ze zbioru tych 20). Dlatego też
skorzystałem z tego zbioru do własnych badań dzieląc emotikony na wyrażające
wydźwięk pozytywny i negatywny w następujący sposób \footnote{emotikona
\texttt{D:} została pominięta, gdyż pokrywała więcej przypadków niż tylko
użycie emotikony (np.: \texttt{Accepte\textbf{d:} Mary, John, Jane})}:

\begin{table}[ht!]  
\begin{center}  
\begin{tabular}{|c|r|l|}
\hline
Emotikona & Popularność & Wydźwięk
\\ \hline
\texttt{:)} & $33.4\%$ & pozytywny \\ \hline
\texttt{:D} & $11.0\%$ & pozytywny \\ \hline
\texttt{:(} & $7.9\%$ & negatywny \\ \hline
\texttt{;)} & $7.5\%$ & pozytywny \\ \hline
\texttt{:-)} & $4.4\%$ & pozytywny \\ \hline
\texttt{:P} & $3.7\%$ & pozytywny \\ \hline
\texttt{=)} & $3.7\%$ & pozytywny \\ \hline
\texttt{(:} & $2.8\%$ & pozytywny \\ \hline
\texttt{;-)} & $2.2\%$ & pozytywny \\ \hline
\texttt{:/} & $1.9\%$ & negatywny \\ \hline
\texttt{XD} & $1.9\%$ & pozytywny \\ \hline
\texttt{=D} & $1.5\%$ & pozytywny \\ \hline
\texttt{:O} & $1.1\%$ & pozytywny \\ \hline
\texttt{=]} & $1.1\%$ & pozytywny \\ \hline
\texttt{;D} & $1.0\%$ & pozytywny \\ \hline
\texttt{:]} & $1.0\%$ & pozytywny \\ \hline
\texttt{:-(} & $0.8\%$ & negatywny \\ \hline
\texttt{=/} & $0.8\%$ & negatywny \\ \hline
\texttt{=(} & $0.8\%$ & negatywny \\ \hline
\end{tabular} 
\end{center} 
\caption{Wydźwięk emotikon}
\label{tab:wydzwiek-emotikon}
\end{table}

Następnie przeglądnięto wszystkie tweety z emotikonami zliczając liczbę
występowania wyrazów w kontekście pozytywnym i negatywnym.
Najpierw badano sentyment całego wpisu (na podstawie emotikony -- gdy była ich
większa ilość wybierano ten sentyment, który przeważał) a następnie dla każdego
wyrazu z tego wpisu zwiększano licznik odpowiednio wystąpień pozytywnych lub
negatywnych. Oczywiście wpisy były już poddane normalizacji.
W ten sposób uzyskano słownik sentymentu zbudowany z zebranych danych, który
zawierał 34183 słowa, a najpopularniejsze z nich to:


\begin{table}[ht!]  
\begin{center}  
\begin{tabular}{|l|r|r|r|r|}
\hline
Słowo & Wyst. pozytywne  & Wyst. negatywne 
& Pozytywność\tablefootnote{Wartość liczona jako: \texttt{pozytywne / (pozytywne +
negatywne)} -- tylko na potrzeby niniejszej tabeli, nieużywana w algorytmie}
& Valence
\\ \hline 
win & 4206 & 598 & 87.6 \% & 0.845 \\ \hline
good & 3916 & 435 & 90.0 \% & 0.903 \\ \hline
game & 3016 & 1012 & 74.9 \% & 0.301 \\ \hline
goal & 2305 & 584 & 79.8 \% & 0.477 \\ \hline
today & 2019 & 526 & 79.3 \% & 0.477 \\ \hline
time & 1844 & 404 & 82.0 \% & 0.602 \\ \hline
dont & 1461 & 775 & 65.3 \% & 0.000 \\ \hline
match & 1669 & 449 & 78.8 \% & 0.477 \\ \hline
great & 1885 & 160 & 92.2 \% & 1.041 \\ \hline
love & 1837 & 202 & 90.1 \% & 0.954 \\ \hline
\end{tabular} 
\end{center} 
\caption{Liczba występowania najpopularniejszych słów w zbudowanych słowniku
sentymentu}
\label{tab:liczebnosc-slow-sentymentu}
\end{table}

Zgodnie z algorytmem wartość \textit{valence} używana jest w dalszych
obliczeniach. Dla każdego wpisu wyliczana jest średnia arytmetyczna tych
wielkości przypisanych do każdego słowa. Wynik ten jest wartością
\textit{valence} danego wpisu. Poniżej prezentuję przykładowe wyniki wyliczania
tej wielkości:
\clearpage
\begin{table}[ht!]  
\begin{center}  
\begin{tabular}{|p{12mm}|p{70mm}|p{63mm}|}
\hline
Valence & Wpis & Składowe 
\\ \hline 
0.6261 POS & Just seen you in the crowd at Chelsea game! @domashman http://t.co/NjovoZdgZ3 & {game=0.4740, crowd=0.7782}
\\ \hline
0.5909 POS & RT @BTSP: \#PRIZEDRAW If Arsenal win tonight one lucky person
will win a personalised BTSP mug! Simply RT \& follow to enter!
http://t.co/9m... & {lucky=0.4613, tonight=0.6873, btsp=0.3010, person=0.4232, personalised=0.3010, enter=0.5351, follow=1.2229, win=0.8465, mug=0.4771, simply=0.3979}
\\ \hline
0.6199 POS & Liking the brightness of this Napoli kit \#tempted &
{liking=0.8062, kit=0.4337} \\ \hline
0.0305 NEG & @ricktaylor1987 You're not watching Arsenal? &
{not\_watching=0.0305} \\ \hline
0.1234 NEG & Poor start\#AFC & {poor=-0.2848, start=0.5317}
\\ \hline
0.1807 NEG & Do Arsenal have any players who don't fall down with ease?
\#SwimmingTeam & {players=0.3684, not\_fall=-0.3979, not\_ease=0.4771,
dont=0.2751} \\ \hline
\end{tabular} 
\end{center} 
\caption{Wynik działania algorytmu analizy sentymentu na przykładowych wpisach}
\end{table}

Określenie sentymentu wpisu odbywa się zgodnie z równaniem:
\begin{equation}
S(t) =
\begin{cases}
POS & valence(t) > AVG\_VALENCE \\
NEG & valence(t) <= AVG\_VALENCE \\
\end{cases}
\end{equation}
Wielkość $AVG\_VALENCE$ jest średnią arytmetyczną wartości $valence$
wszystkich wpisów. W moich badaniach wartość ta wyniosła $0.4786984978198536$.

Powyższa metoda została zastosowana na wszystkich wpisach, które nie posiadają
emotikon określając ich sentyment.

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ANALIZA SIECI SPOŁECZNYCH
\section{Analiza sieci społecznych}
\label{section:siecispoleczne}
\subsection{Model grafowy}
% wykorzystanie reply, retweet
\subsection{Wykrywanie grup}
% gephi, modularity
\subsection{Badanie podobieństwa}
% algorytm podobieństwa grafów, podobieństwa krawędzi




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% WYKORZYSTANIE GEOLOKACJI
\section{Wykorzystanie geolokacji}
\label{section:wykorzystaniegeolokacji}
% tweety z geolokacją
% wyciąganie informacji o miejscu - Open Street Map
% zastosowanie: odl. między użytkownikiami, od stadionu, dzielnice